# import the necessary packages
from Config import config_faces as config
from helpers.handler import iou, nms
from datetime import datetime
from imutils import paths
import dlib
import numpy as np
import cv2
import os

# create the positive and negative image path 
for dirPath in (config.positive_Path, config.negative_Path):
	# if directory doesn't exist create it
	if not os.path.exists(dirPath):
		os.makedirs(dirPath)

# positive, negative image trackers
totalPos = 0
totalNeg = 0

# grab database of processed images
print("[INFO] Loading the face annotations...")
# open the annotation
rows = open(config.face_db).read()
# split in new line | rows -> [image location, startx, starty, endx, endy]
rows = rows.strip().split("\n")[:10]

# initialize the dlib cnn with weights
dlib_cnn = dlib.cnn_face_detection_model_v1(config.d_weight)

# loop through each image
for (count, row) in enumerate(rows):
	print("[INFO] Processing image {} of {}...".format(count + 1, len(rows)))
	# extract contents
	(imagePath, startx, starty, endx, endy) = row.split("\t")
	
	# extract the file name
	file_ = imagePath.split("\\")[-1]
	spot_find = file_.rfind(".")
	file_=file_[:spot_find]

	# load image
	image = cv2.imread(imagePath)
	# image dimensions
	(h, w) = image.shape[:2] 
	# storage for ground truth boxes
	gtBoxes = []

	if "landmark_aligned_face" in file_:
		# obtain bounding box from image
		f_face = dlib_cnn(image, 1)

		for face in f_face:
			# bounding box
			startx = max(0, face.rect.left())
			starty = max(0, face.rect.top())
			endx = min(w, face.rect.right())
			endy = min(h, face.rect.bottom())
	else:
		# remove boxes outside boundary
		startx = max(0, int(startx))
		starty = max(0, int(starty))
		endx = min(w, int(endx))
		endy = min(h, int(endy))

	# insert in ground truth box
	gtBoxes.append((int(startx), int(starty), int(endx), int(endy)))

	# selective search run on list of proposed boxes -> using quality here
	# at run time Fast should be used
	ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
	ss.setBaseImage(image)
	ss.switchToSelectiveSearchFast()
	rects = ss.process()
	proposedRects = []

	# loop over the rectangles generated by selective search
	for (x, y, w, h) in rects:
		# convert to startx, starty, endx, endy
		proposedRects.append((x, y, w + x, y + h))

	# count number of positive and negative regions saved
	posROI = 0
	negROI = 0

	# loop over the max number of region proposals
	for proposedRect in proposedRects[:config.max_proposals]:
		# unpack the proposed rectangle box
		(propStartX, propStartY, propEndX, propEndY) = proposedRect

		# loop over the ground truth boxes
		for gtBox in gtBoxes:
			# calculate iou
			iou_ = iou(gtBox, proposedRect)

			# unpack the proposed rectangle box
			(gtStartX, gtStartY, gtEndX, gtEndY) = gtBox 			

			# initialize the ROI and output path
			roi = None
			outputPath = None

			# check to see if greater than 70% and we are below count limit
			if iou_ > 0.7 and posROI <= config.max_pos:
				# extract the region and derive output path
				roi = image[propStartY:propEndY, propStartX:propEndX]
				file_name = "{}_{}.png".format(file_,posROI)
				outputPath = os.path.sep.join([config.positive_Path, file_name])

				# increment positive counter
				posROI += 1
				totalPos += 1

			# check if the bounding box falls within the ground truth
			fullOver = propStartX >= gtStartX
			fullOver = fullOver and propStartY >= gtStartY
			fullOver = fullOver and propEndX <= gtEndX
			fullOver = fullOver and propEndY <= gtEndY

			# negative case, not full over lap and less than 5 %
			if not fullOver and iou_ < 0.05 and negROI <= config.max_neg:
				# extract the region and derive output path
				roi = image[propStartY:propEndY, propStartX:propEndX]
				# obtain filename
				file_name = "{}.png".format(totalNeg)
				outputPath = os.path.sep.join([config.negative_Path, file_name])

				# increment positive counter
				negROI += 1
				totalNeg += 1

			# if roi and output path exist. resize the image to given input dimensions
			if roi is not None and outputPath is not None:
				roi = cv2.resize(roi, config.input_dim, interpolation=cv2.INTER_CUBIC)
				cv2.imwrite(outputPath, roi)

# END OF CODE








